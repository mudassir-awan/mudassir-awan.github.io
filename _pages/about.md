---
permalink: /
title: " "
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- <h2>About me</h2> -->
<!-- <p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 20px;">
  I'm a research assistant at <a href="http://haptics.khu.ac.kr/">Haptics and Virtual Reality Lab</a> and a MS-PHD combined candidate at <a href="https://www.khu.ac.kr/eng/main/index.do">Kyung Hee University</a> in South Korea. I'm advised by <a href="http://haptics.khu.ac.kr/jeon/">Professor Seokhee Jeon</a> and work on data-driven modeling and rendering of haptic properties to generate realistic haptic feedback in VR environments.
</p>

<p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 20px;">
  My research primarily focuses on modeling and rendering of haptic textures using both online and offline approaches. I specialize in handling complex time series data and applying signal processing techniques. I have also utilized these skills in the context of teleoperation systems, where real-time and accurate rendering of haptic textures is crucial for remote operators.
</p>

<p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 20px;">
  Additionally, I explore the development of novel encountered type haptic devices such as haptic drones and wearable haptic devices in VR and AR applications.
</p> -->



<p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 15px; padding-left: 40px; padding-right: 40px;">
  I'm a research assistant at <a href="http://haptics.khu.ac.kr/">Haptics and Virtual Reality Lab</a> and a MS-PHD combined student at <a href="https://www.khu.ac.kr/eng/main/index.do">Kyung Hee University</a> in South Korea. I'm advised by <a href="http://haptics.khu.ac.kr/jeon/">Professor Seokhee Jeon</a> and work on data-driven modeling and rendering of haptic properties to generate realistic haptic feedback in VR environments.
</p>

<p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 15px; padding-left: 40px; padding-right: 40px;">
  My research primarily focuses on modeling and rendering of haptic textures using both online and offline approaches. I specialize in handling complex time series data and applying signal processing techniques. I have also utilized these skills in the context of teleoperation systems, where real-time and accurate rendering of haptic textures is crucial for remote operators.
</p>

<p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 15px; padding-left: 40px; padding-right: 40px;">
  Additionally, I explore the development of novel encountered type haptic devices such as haptic drones and wearable haptic devices in VR and AR applications.
</p>

<p style="font-size: 14px; text-align: justify; line-height: 1.5; margin-bottom: 15px; padding-left: 40px; padding-right: 40px;">
  <a href="http://mudassir-awan.github.io/files/Mudassir_Resume_2023.pdf">My Full CV</a>  
</p>




<!-- **<u>News</u>** -->
<h2>News</h2>
<!-- <ul style="margin-bottom: 20px; text-align: justify; font-size: 14px; "> -->
<ul style="margin-bottom: 20px;  font-size: 14px; ">

  <li style="line-height: 1.5;">One paper got accepted at <a href="https://vrst.acm.org/vrst2023/">VRST-2023</a> conference on "Predicting Perceptual Haptic Attributes of Textured Surface from Tactile Data Based on Deep CNN-LSTM Network" (Sept 2023).</li>

  <li style="line-height: 1.5;">One paper got accepted at <a href="https://www.kiise.or.kr/conference/kcc/2023/">KCC-2023</a> conference on "Design and Evaluation of Lightweight Deep Learning Models for Synthesizing Haptic Surface Textures" (June 2023).</li>

  <!-- <li style="line-height: 1.5;"> Join us at <a href="https://2023.ubiquitousrobots.org/">UR-2023</a> conference,  <a href="https://www.meethawaii.com/convention-center/">Hwaaii Convention Center </a>  for our paper presnetaion on "Drone Haptics for 3DOF Force Feedback" on 26th June 2023.</li> -->
  <!-- <li style="line-height: 1.5;">Two papers got accepted in Korea Computer Congress <a href="https://www.kiise.or.kr/conference/kcc/2023/">[KCC-2023] </a> Confernce at Jeju Island, South Korea.</li> -->
  <li style="line-height: 1.5;">I will be presenting our paper on Model Mediated Teleoperation for online Texture modeling and rendering at <a href="https://www.icra2023.org/">ICRA-2023</a> on 1st June, 2023 at Excel London.</li>
  <li style="line-height: 1.5;">One paper got accepted at <a href="https://2023.ubiquitousrobots.org/">UR-2023</a> conference on "Drone Haptics for 3DOF Force Feedback" (April 2023).</li>
  <li style="line-height: 1.5;">One paper got accepted at <a href="https://www.icra2023.org/">ICRA-2023</a> conference titled "Model Mediated Teleoperation for real time haptic texture modeling and rendering" (Feb 2023).</li>
  <!-- <li style="line-height: 1.5;">One paper got accepted at <a href="https://hcikorea.org/">HCI Korea-2023</a> conference on "Haptic Texture Classification using Transformers" (Jan 2023).</li> -->



</ul>



<h2>Selected Publications</h2> 

You can also find the full list of my publications [<span style="color:blue">here</span>](https://mudassir-awan.github.io/publications/)

<table style="width: 100%; border-collapse: collapse; border: 0;">
  <tr>
    <td style="width: 25%; text-align: center; border: none;">
      <img src="/images/VRST.png" alt="Profile Picture" width="160" height="300" style="margin-right: 10px;">
    </td>
    <td style="width: 75%; text-align: justify; border: none;">
      <h3><a href="https://mudassir-awan.github.io/publications/PerceptualAttributes">Predicting Perceptual Haptic Attributes of Textured Surface from Tactile Data Based on Deep CNN-LSTM Network</a>(VRST 2023)</h3>
      <p>
        This paper presents a method to predict human-perceived haptic attributes from tactile signals (acceleration) when a surface is stroked. Using data from 25 texture samples, a five-dimensional haptic space is defined through human feedback, while a physical signal space is created from tool-based interactions. A CNN-LSTM network maps between these spaces. The resulting algorithm, which translates acceleration data to haptic attributes, demonstrated superior performance on unseen textures compared to other models.
      </p>
      <p><a href="https://dl.acm.org/doi/10.1145/3611659.3615714" target="_blank">Full Paper</a> &nbsp;&nbsp;&nbsp; <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:govmnYYkzxoJ:scholar.google.com/&output=citation&scisdr=ClET3ZDtEPisiJJfG0Y:AFWwaeYAAAAAZTtZA0ZAs13tSbirlDUuAEiBf1Q&scisig=AFWwaeYAAAAAZTtZA1BmVQXsktQEa70agIXX2fE&scisf=4&ct=citation&cd=-1&hl=ko" target="_blank">Bibtex</a></p>
    </td>
  </tr>
</table>

<table style="width: 100%; border-collapse: collapse; border: 0;">
  <tr>
    <td style="width: 25%; text-align: center; border: none;">
      <img src="/images/mmt.png" alt="Profile Picture" width="160" height="300" style="margin-right: 10px;">
    </td>
    <td style="width: 75%; text-align: justify; border: none;">
      <h3><a href="https://mudassir-awan.github.io/publications/teleoperation">Model-Mediated Teleoperation for Remote Haptic Texture Sharing: Initial Study of Online Texture Modeling and Rendering</a>(ICRA 2023 )</h3>
      <p>
        This paper presents the first model-mediated teleoperation (MMT) framework capable of sharing surface haptic texture. It enables the collection of physical signals on the follower side, which are used to build and update a local texture simulation model on the leader side. This approach provides real-time, stable, and accurate feedback of texture. The paper includes an implemented proof-of-concept system that showcases the potential of this approach for remote texture sharing.
      </p>
      <p><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VCllBHIAAAAJ&citation_for_view=VCllBHIAAAAJ:9yKSN-GCB0IC" target="_blank">Full Paper</a> &nbsp;&nbsp;&nbsp; <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:ig0GiCPhszMJ:scholar.google.com/&output=citation&scisdr=ClET3ZDtEOqwiJJc0jU:AFWwaeYAAAAAZTtayjU7FZSGVmQT_SL38W-XPwA&scisig=AFWwaeYAAAAAZTtayhVJ5oYcUeSiPYHQs1BGdfE&scisf=4&ct=citation&cd=-1&hl=ko" target="_blank">Bibtex</a></p>
    </td>
  </tr>
</table>


<table style="width: 100%; border-collapse: collapse; border: 0;">
  <tr>
    <td style="width: 25%; text-align: center; border: none;">
      <img src="/images/drone.png" alt="Profile Picture" width="160" height="300" style="margin-right: 10px;">
    </td>
    <td style="width: 75%; text-align: justify; border: none;">
      <h3><a href="https://mudassir-awan.github.io/publications/drone">DroneHaptics - Encountered Type Haptic Interface Using Dome-Shaped Drone for 3-DoF Force Feedback</a>(UR 2023)</h3>
      <p>
        This paper introduces a dome-shaped haptic drone with a hemispherical cage made of aluminum mesh. The cage enables controllable 3D force feedback, improving usability and user safety. Experimental measurements and mathematical formulations establish an accurate force-thrust relationship. The system's force rendering accuracy was evaluated, achieving a low error rate of less than 8.6%, ensuring perceptually accurate force feedback.
      </p>
      <p><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VCllBHIAAAAJ&citation_for_view=VCllBHIAAAAJ:2osOgNQ5qMEC" target="_blank">Full Paper</a> &nbsp;&nbsp;&nbsp; <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:hNtm8v4PV_MJ:scholar.google.com/&output=citation&scisdr=ClET3ZDtEOqwiJJdB_o:AFWwaeYAAAAAZTtbH_rIBtvOpx4fMntQOvBx14M&scisig=AFWwaeYAAAAAZTtbHyhZORLPAKyrrlhVwM5Ynyg&scisf=4&ct=citation&cd=-1&hl=ko" target="_blank">Bibtex</a></p>
    </td>
  </tr>
</table>

<style>
  .bibtex-content {
    display: none;
    width: 100%;
    background-color: #f9f9f9; /* Optional: Add a background color for clarity */
    border: 1px solid #ddd;    /* Optional: Add a border for clarity */
    padding: 10px;             /* Optional: Add some padding */
  }
</style>

<script>
  function toggleBibtex(bibtexId) {
    var element = document.getElementById(bibtexId);
    if (element.style.display === "none") {
      element.style.display = "block";
    } else {
      element.style.display = "none";
    }
  }
</script>

<table style="width: 100%; border-collapse: collapse; border: 0;">
  <tr>
    <td style="width: 25%; text-align: center; border: none;">
      <img src="/images/drone.png" alt="Profile Picture" width="160" height="300" style="margin-right: 10px;">
    </td>
    <td style="width: 75%; text-align: justify; border: none;">
      <h3><a href="https://mudassir-awan.github.io/publications/drone">DroneHaptics - Encountered Type Haptic Interface Using Dome-Shaped Drone for 3-DoF Force Feedback</a>(UR 2023)</h3>
      <p>
        This paper introduces a dome-shaped haptic drone with a hemispherical cage made of aluminum mesh. The cage enables controllable 3D force feedback, improving usability and user safety. Experimental measurements and mathematical formulations establish an accurate force-thrust relationship. The system's force rendering accuracy was evaluated, achieving a low error rate of less than 8.6%, ensuring perceptually accurate force feedback.
      </p>
      <p>
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VCllBHIAAAAJ&citation_for_view=VCllBHIAAAAJ:2osOgNQ5qMEC" target="_blank">Full Paper</a> &nbsp;&nbsp;&nbsp;
        <button class="bibtex-button" onclick="toggleBibtex('bibtexDrone')">Bibtex</button>
        <div class="bibtex-content" id="bibtexDrone">
          <pre>
@inproceedings{awan2023dronehaptics,
  title={DroneHaptics: Encountered-Type Haptic Interface Using Dome-Shaped Drone for 3-DoF Force Feedback},
  author={Awan, Mudassir Ibrahim and Raza, Ahsan and Jeon, Seokhee},
  booktitle={2023 20th International Conference on Ubiquitous Robots (UR)},
  pages={195--200},
  year={2023},
  organization={IEEE}
}
          </pre>
        </div>
      </p>
    </td>
  </tr>
</table>







<!-- **<u>Selected Publications</u>** -->
<!-- <h2>Selected Publications</h2>

You can also find the full list of my publications [<span style="color:blue">here</span>](https://mudassir-awan.github.io/publications/)


[Model-Mediated Teleoperation for Remote Haptic Texture Sharing: Initial Study of Online Texture Modeling and Rendering](https://mudassir-awan.github.io/publications/teleoperation)  **(ICRA)** 


This paper presents the first model-mediated teleoperation (MMT) framework capable of sharing surface haptic texture. It enables the collection of physical signals on the follower side, which are used to build and update a local texture simulation model on the leader side. This approach provides real-time, stable, and accurate feedback of texture. The paper includes an implemented proof-of-concept system that showcases the potential of this approach for remote texture sharing.
[Download paper here](http://mudassir-awan.github.io/files/MMT.pdf)

[DroneHaptics - Encountered Type Haptic Interface Using Dome-Shaped Drone for 3-DoF Force Feedback](https://mudassir-awan.github.io/publications/drone) **(UR)** 

This paper introduces a dome-shaped haptic drone with a hemispherical cage made of aluminum mesh. The cage enables controllable 3D force feedback, improving usability and user safety. Experimental measurements and mathematical formulations establish an accurate force-thrust relationship. The system's force rendering accuracy was evaluated, achieving a low error rate of less than 8.6%, ensuring perceptually accurate force feedback. [Download paper here](http://mudassir-awan.github.io/files/DroneHaptics.pdf) -->


<!-- <h2>Selected Publications</h2>

You can also find the full list of my publications [<span style="color:blue">here</span>](https://mudassir-awan.github.io/publications/)

<div style="display: flex; align-items: flex-start;">
  <div style="flex: 1; text-align: justify;">
    <h3><a href="https://mudassir-awan.github.io/publications/teleoperation">Model-Mediated Teleoperation for Remote Haptic Texture Sharing: Initial Study of Online Texture Modeling and Rendering</a>(ICRA)</h3>

    <div style="display: flex;">
      <div style="flex: 1;">
        <img src="/images/profile.png" alt="Profile Picture" width="150" height="200" style="margin-right: 30px;">
      </div>
      <div style="flex: 3;">
        <p>
          This paper presents the first model-mediated teleoperation (MMT) framework capable of sharing surface haptic texture. It enables the collection of physical signals on the follower side, which are used to build and update a local texture simulation model on the leader side. This approach provides real-time, stable, and accurate feedback of texture. The paper includes an implemented proof-of-concept system that showcases the potential of this approach for remote texture sharing.
          
          <a href="http://mudassir-awan.github.io/files/MMT.pdf">Download paper here</a>
        </p>
      </div>
    </div>
  </div>
</div>

<div style="display: flex; align-items: flex-start;">
  <div style="flex: 1; text-align: justify;">
    <h3><a href="https://mudassir-awan.github.io/publications/drone">DroneHaptics - Encountered Type Haptic Interface Using Dome-Shaped Drone for 3-DoF Force Feedback</a> (UR)</h3>

    <div style="display: flex;">
      <div style="flex: 1;">
        <img src="/images/profile.png" alt="Profile Picture" width="150" height="200" style="margin-right: 20px;">
      </div>
      <div style="flex: 3;">
        <p>
          This paper introduces a dome-shaped haptic drone with a hemispherical cage made of aluminum mesh. The cage enables controllable 3D force feedback, improving usability and user safety. Experimental measurements and mathematical formulations establish an accurate force-thrust relationship. The system's force rendering accuracy was evaluated, achieving a low error rate of less than 8.6%, ensuring perceptually accurate force feedback.
          
          <a href="http://mudassir-awan.github.io/files/DroneHaptics.pdf">Download paper here</a>
        </p>
      </div>
    </div>
  </div>
</div>

 -->
