---
permalink: /
title: " "
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a research assistant at [Haptics and Virtual Reality Lab](http://haptics.khu.ac.kr/) and a MS-PHD combined candidate at [Kyung Hee University](https://www.khu.ac.kr/eng/main/index.do) in South Korea. I'm advised by [Professor Seokhee Jeon](http://haptics.khu.ac.kr/jeon/) and work on data-driven modeling and rendering of haptic properties to generate realistic haptic feedback in VR environments. 

My research primarily focuses on modeling and rendering of haptic textures using both online and offline approaches. I specialize in handling complex time series data and applying signal processing techniques. I have also utilized these skills in the context of teleoperation systems, where real-time and accurate rendering of haptic textures is crucial for remote operators.

Additionally, I explore the development of novel encountered type haptic devices such as haptic drones and wearable haptic devices in VR and AR applications.



**News** 

- I will be presenting our paper on Model Mediated Teleoperation for online Texture modeling and rendering at [ICRA-2023](https://www.icra2023.org/) on [1st June,2023 at Excel London](https://www.icra2023.org/programme-1fc3).

- One paper got accepted at [UR-2023](https://2023.ubiquitousrobots.org/) conference on "Drone Haptics for 3DOF Force Feedback"  **(April 2023)**.

- One paper got accepted at [ICRA-2023](https://www.icra2023.org/) conference titled "Model Mediated Teleoperation for Texture rendering" **(Feb 2023)**.

- One paper got accepted at [HCI Korea-2023](https://hcikorea.org/) conference on "Hatic Texture Classification using Transformers" **(Jan 2023)**.



**Selected Publications**


[Model-Mediated Teleoperation for Remote Haptic Texture Sharing: Initial Study of Online Texture Modeling and Rendering](https://mudassir-awan.github.io/publications/teleoperation)  **(ICRA)** 

This paper presents the first model-mediated teleoperation (MMT) framework capable of sharing surface haptic texture. It enables the collection of physical signals on the follower side, which are used to build and update a local texture simulation model on the leader side. This approach provides real-time, stable, and accurate feedback of texture. The paper includes an implemented proof-of-concept system that showcases the potential of this approach for remote texture sharing.
[Download paper here](http://mudassir-awan.github.io/files/MMT.pdf)

[DroneHaptics - Encountered Type Haptic Interface Using Dome-Shaped Drone for 3-DoF Force Feedback](https://mudassir-awan.github.io/publications/drone) **(UR)** 

This paper introduces a dome-shaped haptic drone with a hemispherical cage made of aluminum mesh. The cage enables controllable 3D force feedback, improving usability and user safety. Experimental measurements and mathematical formulations establish an accurate force-thrust relationship. The system's force rendering accuracy was evaluated, achieving a low error rate of less than 8.6%, ensuring perceptually accurate force feedback.